diff --git a/data_loaders/get_data.py b/data_loaders/get_data.py
index 48e3496..1410eca 100644
--- a/data_loaders/get_data.py
+++ b/data_loaders/get_data.py
@@ -23,7 +23,7 @@ def get_collate_fn(name, hml_mode='train'):
         return all_collate
 
 
-def get_dataset(name, num_frames, split='train', hml_mode='train', control_joint=0, density=100):
+def get_dataset(name, num_frames, split='train', hml_mode='train', control_joint=0, density=100):    
     DATA = get_dataset_class(name)
     if name in ["humanml", "kit"]:
         dataset = DATA(split=split, num_frames=num_frames, mode=hml_mode, control_joint=control_joint, density=density)
diff --git a/data_loaders/humanml/common/quaternion.py b/data_loaders/humanml/common/quaternion.py
index e2daa00..8484852 100644
--- a/data_loaders/humanml/common/quaternion.py
+++ b/data_loaders/humanml/common/quaternion.py
@@ -318,9 +318,9 @@ def quaternion_to_cont6d(quaternions):
 
 
 def cont6d_to_matrix(cont6d):
-    assert cont6d.shape[-1] == 6, "The last dimension must be 6"
+    assert cont6d.shape[-1] == 6, "The last dimension must be 6"    
     x_raw = cont6d[..., 0:3]
-    y_raw = cont6d[..., 3:6]
+    y_raw = cont6d[..., 3:6]      
 
     x = x_raw / torch.norm(x_raw, dim=-1, keepdim=True)
     z = torch.cross(x, y_raw, dim=-1)
diff --git a/data_loaders/humanml/data/dataset.py b/data_loaders/humanml/data/dataset.py
index 9e2353e..79504cc 100644
--- a/data_loaders/humanml/data/dataset.py
+++ b/data_loaders/humanml/data/dataset.py
@@ -44,15 +44,16 @@ class Text2MotionDatasetV2(data.Dataset):
 
         new_name_list = []
         length_list = []
+        print(f'dataset size: {len(id_list)}')
         for name in tqdm(id_list):
-            try:
-                motion = np.load(pjoin(opt.motion_dir, name + '.npy'))
-                if (len(motion)) < min_motion_len or (len(motion) >= 200):
+            try:                
+                motion = np.load(pjoin(opt.motion_dir, name + '.npy'))                
+                if (len(motion)) < min_motion_len or (len(motion) >= 200):                    
                     continue
                 text_data = []
                 flag = False
-                with cs.open(pjoin(opt.text_dir, name + '.txt')) as f:
-                    for line in f.readlines():
+                with cs.open(pjoin(opt.text_dir, name + '.txt')) as f:                    
+                    for line in f.readlines():                        
                         text_dict = {}
                         line_split = line.strip().split('#')
                         caption = line_split[0]
@@ -64,10 +65,10 @@ class Text2MotionDatasetV2(data.Dataset):
 
                         text_dict['caption'] = caption
                         text_dict['tokens'] = tokens
-                        if f_tag == 0.0 and to_tag == 0.0:
+                        if f_tag == 0.0 and to_tag == 0.0:                            
                             flag = True
                             text_data.append(text_dict)
-                        else:
+                        else:                            
                             try:
                                 n_motion = motion[int(f_tag*20) : int(to_tag*20)]
                                 if (len(n_motion)) < min_motion_len or (len(n_motion) >= 200):
@@ -85,15 +86,19 @@ class Text2MotionDatasetV2(data.Dataset):
                                 print(line_split[2], line_split[3], f_tag, to_tag, name)
                                 # break
 
-                if flag:
+                if flag:                    
                     data_dict[name] = {'motion': motion,
                                        'length': len(motion),
                                        'text': text_data}
                     new_name_list.append(name)
                     length_list.append(len(motion))
-            except:
+            except Exception as e:
+                print(e)
                 pass
-
+        
+        print(f'new_name_list: {new_name_list[:10]}')        
+        print(f'length_list: {length_list[:10]}')
+        print("----------------------")
         name_list, length_list = zip(*sorted(zip(new_name_list, length_list), key=lambda x: x[1]))
 
         self.mean = mean
@@ -398,6 +403,8 @@ class HumanML3D(data.Dataset):
         opt.checkpoints_dir = pjoin(abs_base_path, opt.checkpoints_dir)
         opt.data_root = pjoin(abs_base_path, opt.data_root)
         opt.save_root = pjoin(abs_base_path, opt.save_root)
+        print(f'data_root: {opt.data_root}')
+        print(f'save_root: {opt.save_root}')
         opt.meta_dir = './dataset'
         self.opt = opt
         print('Loading dataset %s ...' % opt.dataset_name)
@@ -438,5 +445,5 @@ class HumanML3D(data.Dataset):
 
 # A wrapper class for t2m original dataset for MDM purposes
 class KIT(HumanML3D):
-    def __init__(self, mode, datapath='./dataset/kit_opt.txt', split="train", **kwargs):
+    def __init__(self, mode, datapath='./dataset/kit_opt.txt', split="train", **kwargs):        
         super(KIT, self).__init__(mode, datapath, split, **kwargs)
\ No newline at end of file
diff --git a/diffusion/gaussian_diffusion.py b/diffusion/gaussian_diffusion.py
index 60e03b8..bcfb392 100644
--- a/diffusion/gaussian_diffusion.py
+++ b/diffusion/gaussian_diffusion.py
@@ -429,6 +429,16 @@ class GaussianDiffusion:
             x_ = x_ * self.std + self.mean
             n_joints = 22 if x_.shape[-1] == 263 else 21
             joint_pos = recover_from_ric(x_, n_joints)
+            
+            """ print("=====================================")            
+            r_wrist_pos = joint_pos[0, :, 21]            
+            r_elbow_pos = joint_pos[0, :, 19]            
+            print(r_wrist_pos)
+            print(r_elbow_pos)
+            direction = r_wrist_pos-r_elbow_pos            
+            direction = torch.cat((direction[:, :1], direction[:, 2:]), dim=1)              
+            print(direction) """
+
             if n_joints == 21:
                 joint_pos = joint_pos * 0.001
                 hint = hint * 0.001
diff --git a/sample/generate.py b/sample/generate.py
index 711288e..5038c19 100644
--- a/sample/generate.py
+++ b/sample/generate.py
@@ -17,12 +17,14 @@ import data_loaders.humanml.utils.paramUtil as paramUtil
 from data_loaders.humanml.utils.plot_script import plot_3d_motion
 import shutil
 from data_loaders.tensors import collate
-from utils.text_control_example import collate_all
+from utils.model_test import collate_all
+#from utils.text_control_example import collate_all
 from os.path import join as pjoin
 
 
 def main():
     args = generate_args()
+    print(f'args: {args}')
     fixseed(args.seed)
     out_path = args.output_dir
     name = os.path.basename(os.path.dirname(args.model_path))
@@ -34,8 +36,13 @@ def main():
     is_using_data = not any([args.text_prompt])
     dist_util.setup_dist(args.device)
     if out_path == '':
+        """
         out_path = os.path.join(os.path.dirname(args.model_path),
-                                'samples_{}_{}_seed{}'.format(name, niter, args.seed))
+                                'joint1_{}_{}_seed{}'.format(name, niter, args.seed))
+        """        
+        print(f'output name: {args.output_name}')
+        out_path = os.path.join(os.path.dirname(args.model_path),
+                                '{}_{}_{}'.format(args.output_name, name, args.seed))
         if args.text_prompt != '':
             out_path += '_' + args.text_prompt.replace(' ', '_').replace('.', '')
 
@@ -66,9 +73,14 @@ def main():
     # (specify through the --seed flag)
     args.batch_size = args.num_samples  # Sampling a single batch from the testset, with exactly args.num_samples
 
+
+    print(f"Args: {args}")
+    print(f"guidance_param: {args.guidance_param}")
+    print("---------------------------------------")
+
     print('Loading dataset...')
-    data = load_dataset(args, max_frames, n_frames)
-    total_num_samples = args.num_samples * args.num_repetitions
+    data = load_dataset(args, max_frames, n_frames)    
+    total_num_samples = args.num_samples * args.num_repetitions    
 
     print("Creating model and diffusion...")
     model, diffusion = create_model_and_diffusion(args, data)
@@ -112,7 +124,7 @@ def main():
             model_kwargs['y']['scale'] = torch.ones(args.batch_size, device=dist_util.dev()) * args.guidance_param
 
         sample_fn = diffusion.p_sample_loop
-
+        
         sample = sample_fn(
             model,
             (args.batch_size, model.njoints, model.nfeats, n_frames),
@@ -124,9 +136,12 @@ def main():
             dump_steps=None,
             noise=None,
             const_noise=False,
-        )
+        )        
 
+        print(type(sample))
+        print(sample.shape)
         sample = sample[:, :263]
+        print(sample.shape)
         # Recover XYZ *positions* from HumanML3D vector representation
         if model.data_rep == 'hml_vec':
             n_joints = 22 if sample.shape[1] == 263 else 21
@@ -166,7 +181,7 @@ def main():
                 hint = hint.view(hint.shape[0], hint.shape[1], n_joints, 3)
                 all_hint_for_vis.append(hint.data.cpu().numpy())
 
-        all_motions.append(sample.cpu().numpy())
+        all_motions.append(sample.cpu().numpy())                
         all_lengths.append(model_kwargs['y']['lengths'].cpu().numpy())
 
         print(f"created {len(all_motions) * args.batch_size} samples")
@@ -204,7 +219,7 @@ def main():
 
     sample_files = []
     num_samples_in_out_file = 7
-
+    
     sample_print_template, row_print_template, all_print_template, \
     sample_file_template, row_file_template, all_file_template = construct_template_variables(args.unconstrained)
 
@@ -212,7 +227,7 @@ def main():
         rep_files = []
         for rep_i in range(args.num_repetitions):
             caption = all_text[rep_i*args.batch_size + sample_i]
-            length = all_lengths[rep_i*args.batch_size + sample_i]
+            length = all_lengths[rep_i*args.batch_size + sample_i]            
             motion = all_motions[rep_i*args.batch_size + sample_i].transpose(2, 0, 1)[:length]
             if 'hint' in model_kwargs['y']:
                 hint = all_hint_for_vis[rep_i*args.batch_size + sample_i]
@@ -221,7 +236,20 @@ def main():
             save_file = sample_file_template.format(sample_i, rep_i)
             print(sample_print_template.format(caption, sample_i, rep_i, save_file))
             animation_save_path = os.path.join(out_path, save_file)
-            plot_3d_motion(animation_save_path, skeleton, motion, dataset=args.dataset, title=caption, fps=fps, hint=hint)
+            """
+            print("#############################")
+            print(f'animation path: {animation_save_path}')
+            print(f'skeleton: {skeleton}')            
+            print("motion")
+            print(motion)
+            print(motion.shape)            
+            print(f'dataset: {args.dataset}')
+            print(f'title: {caption}')
+            print(f'fps: {fps}')
+            print(f'hint: {hint}')
+            print(hint.shape)            
+            """            
+            plot_3d_motion(animation_save_path, skeleton, motion, dataset=args.dataset, title=caption, fps=fps, hint=hint)            
             # Credit for visualization: https://github.com/EricGuo5513/text-to-motion
             rep_files.append(animation_save_path)
 
diff --git a/train/training_loop.py b/train/training_loop.py
index a9dea7b..a6510a1 100644
--- a/train/training_loop.py
+++ b/train/training_loop.py
@@ -100,7 +100,8 @@ class TrainLoop:
             )
             self.opt.load_state_dict(state_dict)
 
-    def run_loop(self):
+    def run_loop(self):        
+        print(f'Number of epochs: {self.num_epochs}')
 
         for epoch in range(self.num_epochs):
             print(f'Starting epoch {epoch}')
@@ -180,7 +181,7 @@ class TrainLoop:
                 )
 
             loss = (losses["loss"] * weights).mean()
-            print(loss.item())
+            #print(loss.item())
             log_loss_dict(
                 self.diffusion, t, {k: v * weights for k, v in losses.items()}
             )
diff --git a/utils/parser_util.py b/utils/parser_util.py
index ca473e8..d7badce 100644
--- a/utils/parser_util.py
+++ b/utils/parser_util.py
@@ -165,6 +165,8 @@ def add_generate_options(parser):
                        help="generation mode: both_text_spatial, only_text, only_spatial. Other words will be used as text prompt.")
     group.add_argument("--text_prompt", default='predefined', type=str,
                        help="A text prompt to be generated. If empty, will take text prompts from dataset.")
+    group.add_argument("--output_name", default='test0', type=str,
+                       help="Name of the saved output folder")
 
 
 def add_edit_options(parser):
diff --git a/utils/text_control_example.py b/utils/text_control_example.py
index 53d54eb..3751ee9 100644
--- a/utils/text_control_example.py
+++ b/utils/text_control_example.py
@@ -336,6 +336,7 @@ def head_text_control_example(n_frames=120, raw_mean=None, raw_std=None, index=0
 
     control = control[index:index+1]
     text = text[index:index+1]
+    
 
     # normalize
     control_full = np.zeros((len(control), n_frames, 22, 3)).astype(np.float32)
@@ -646,6 +647,79 @@ def sample_points_forward_back_verticel(n):
         points.append((x, y))
     return points
 
+def ducking_example(n_frames=120, raw_mean=None, raw_std=None, index=0):
+    text = [
+        #head
+        'A person ducks under an obstacle while walking forwards'
+    ]
+    straight_line = straight_forward_uniform(n_frames, indices=[2], scale=5, x_offset=0, y_offset=0.7, z_offset=0.0)
+    print(straight_line)
+    control = [
+        straight_line
+    ]
+    joint_id = np.array([
+        # head 
+        15,
+    ])
+
+    control = control[index:index+1]
+    text = text[index:index+1]
+
+    # normalize
+    control_full = np.zeros((len(control), n_frames, 22, 3)).astype(np.float32)
+    for i in range(len(control)):
+        mask = control[i].sum(-1) != 0
+        control_ = (control[i] - raw_mean.reshape(22, 1, 3)[joint_id[i]]) / raw_std.reshape(22, 1, 3)[joint_id[i]]
+        control_ = control_ * mask[..., np.newaxis]
+        control_full[i, :, joint_id[i], :] = control_
+
+    control_full = control_full.reshape((len(control), n_frames, -1))
+    
+    return text, control_full, joint_id
+
+def hole_in_the_wall(n_frames=120, raw_mean=None, raw_std=None, index=0):
+    text = [
+        # foot
+        'A person plays football',        
+    ]
+    start_frame = 20
+    control = [        
+        # right foot, left wrist, left wrist 
+        [
+            specify_points(n_frames, [[start_frame, 0, 0, 1.5]]),
+            specify_points(n_frames, [[start_frame, -0.2, 0.3, 1.5]]),
+            specify_points(n_frames, [[start_frame, 0.5, 1.3, 1.5]])
+        ],                    
+    ]
+    joint_id = np.array([
+        # right foot, left wrist, left wrist  
+        [10, 11, 20]
+        ])
+    control = np.stack(control)
+
+    # extend controls    
+    control[0, 0, start_frame:190] = control[0, 0, start_frame]
+    control[0, 1, start_frame:190] = control[0, 1, start_frame]
+    control[0, 2, start_frame:190] = control[0, 2, start_frame]
+    #print(control[0, 0, start_frame-10:190])
+    #print(control[0, 1, start_frame-10:190])
+    #print(control[0, 2, start_frame-10:190])
+    #print(control.shape)    
+
+    control = control[index:index+1]
+    text = text[index:index+1]
+    #joint_id = joint_id[index:index+1]
+    
+    # normalize
+    control_full = np.zeros((len(control), n_frames, 22, 3)).astype(np.float32)
+    for i in range(len(control)):
+        mask = control[i].sum(-1) != 0
+        control_ = (control[i] - raw_mean.reshape(22, 1, 3)[joint_id[i]]) / raw_std.reshape(22, 1, 3)[joint_id[i]]
+        control_ = control_ * mask[..., np.newaxis]
+        control_full[i, :, joint_id[i], :] = control_
+
+    control_full = control_full.reshape((len(control), n_frames, -1))
+    return text, control_full, joint_id
 
 def collate_all(n_frames, dataset):
     if dataset == 'humanml':
@@ -657,6 +731,7 @@ def collate_all(n_frames, dataset):
     raw_mean = np.load(pjoin(spatial_norm_path, 'Mean_raw.npy'))
     raw_std = np.load(pjoin(spatial_norm_path, 'Std_raw.npy'))
 
+    
     texts0, hints0, _ = pelvis_dense_text_control_example(n_frames, raw_mean, raw_std, index=0)
     texts1, hints1, _ = pelvis_sparse_text_control_example(n_frames, raw_mean, raw_std, index=0)
     texts2, hints2, _ = wrist_text_control_example(n_frames, raw_mean, raw_std, index=0)
@@ -667,5 +742,9 @@ def collate_all(n_frames, dataset):
     texts6, hints6, _ = combination_text_control_example(n_frames, raw_mean, raw_std, index=0)
     texts7, hints7, _ = motion_inbetweening(n_frames, raw_mean, raw_std, index=0)
     texts = texts0 + texts1 + texts2 + texts3 + texts4 + texts5 + texts6 + texts7
+    print("#############################")
+    print(texts)
+    print(type(texts))
     hints = np.concatenate([hints0, hints1, hints2, hints3, hints4, hints5, hints6, hints7], axis=0)
+
     return texts, hints
\ No newline at end of file
diff --git a/visualize/render_mesh.py b/visualize/render_mesh.py
index 94ace42..0b769ac 100644
--- a/visualize/render_mesh.py
+++ b/visualize/render_mesh.py
@@ -13,7 +13,7 @@ if __name__ == '__main__':
     params = parser.parse_args()
 
     assert params.input_path.endswith('.mp4')
-    parsed_name = os.path.basename(params.input_path).replace('.mp4', '').replace('sample', '').replace('rep', '')
+    parsed_name = os.path.basename(params.input_path).replace('.mp4', '').replace('sample', '').replace('rep', '')    
     sample_i, rep_i = [int(e) for e in parsed_name.split('_')]
     npy_path = os.path.join(os.path.dirname(params.input_path), 'results.npy')
     out_npy_path = params.input_path.replace('.mp4', '_smpl_params.npy')
diff --git a/visualize/vis_utils.py b/visualize/vis_utils.py
index fc4efe9..16c91d0 100644
--- a/visualize/vis_utils.py
+++ b/visualize/vis_utils.py
@@ -9,10 +9,18 @@ from visualize.simplify_loc2rot import joints2smpl
 class npy2obj:
     def __init__(self, npy_path, sample_idx, rep_idx, device=0, cuda=True):
         self.npy_path = npy_path
-        self.motions = np.load(self.npy_path, allow_pickle=True)
-        if self.npy_path.endswith('.npz'):
-            self.motions = self.motions['arr_0']
-        self.motions = self.motions[None][0]
+        self.motions = np.load(self.npy_path, allow_pickle=True)        
+        if self.npy_path.endswith('.npz'):            
+            self.motions = self.motions['arr_0']            
+        self.motions = self.motions[None][0]                
+        print("--------------------------------------------------")
+        print(type(self.motions))
+        print(self.motions.keys())
+        for k in self.motions.keys():
+            print(f'key: {k}')
+            print(self.motions[k])
+            print()
+        print("--------------------------------------------------")
         self.rot2xyz = Rotation2xyz(device='cpu')
         self.faces = self.rot2xyz.smpl_model.faces
         self.bs, self.njoints, self.nfeats, self.nframes = self.motions['motion'].shape
@@ -22,7 +30,7 @@ class npy2obj:
         self.rep_idx = rep_idx
         self.absl_idx = self.rep_idx*self.total_num_samples + self.sample_idx
         self.num_frames = self.motions['motion'][self.absl_idx].shape[-1]
-        self.j2s = joints2smpl(num_frames=self.num_frames, device_id=device, cuda=cuda)
+        self.j2s = joints2smpl(num_frames=self.num_frames, device_id=device, cuda=cuda)        
         self.hint = self.motions['hint'][self.absl_idx]
 
         if self.nfeats == 3:
